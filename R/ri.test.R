ri.test=function(treated.r,control.r,alternative='greater',statistic='mean.diff',exact=FALSE,n.mc=1000){
  
  # Create vectors for r and Z, 
  # and find total number in experiment and number of treated subjects
  r=c(treated.r,control.r);
  Z=c(rep(1,length(treated.r)),rep(0,length(control.r)));
  N=length(r);
  m=length(treated.r);
  
  # Observed test statistic
  if (statistic=='mean.diff'){
    obs.test.stat=mean(r[Z==1])-mean(r[Z==0])
  }else if (statistic=='t.test'){
    pooledsd=((m-1)*var(treated.r)+(N-m-1)*var(control.r))/(N-2)
    obs.test.stat=(mean(treated.r)-mean(control.r))/pooledsd
  }else{
    stop('statistic must be one of mean.diff and t.test')
  }
  
  if (exact==TRUE){
    # Recursive function for finding all subsets of size r from 
    # the set (1,...,n)
    #
    # Based on the following observation: Suppose you single out one of 
    # the elements, say the first. Then the subsets of size r consist of 
    # those that contain the first and those that do not. The first group 
    # may be generated by attaching the first object to each subset 
    # of size r-1 selected from the n-1 others, and the second group 
    # consists of all subsets of size r from the n-1 others.
    subsets=function(n,r,v=1:n){
      if(r<=0) NULL 
      else if(r>=n) v[1:n] 
      else rbind(cbind(v[1],subsets(n-1,r-1,v[-1])),subsets(n-1,r,v[-1]))
    }
    
    # Compute distribution of test statistic over random assignments
    
    # Matrix that contains all possible assignments of subjects 
    # to the treated group
    subsetmat=subsets(N,m); 
    # The r for each subject in the treated group and control group 
    # in the assignments in subsetmat
    treated.r.mat=matrix(r[t(subsetmat)],ncol=m,byrow=T)
    control.r.mat=matrix(rep(0,(N-m)*nrow(subsetmat)),ncol=N-m,byrow=T)
    for(i in 1:nrow(subsetmat)){
      control.r.mat[i,]=r[-subsetmat[i,]]
    }
    
    # Mean of the treated and control groups for the assignments in subsetmat,
    # and corresponding test statistic
    mean.treated.r=apply(treated.r.mat,1,mean);
    mean.control.r=apply(control.r.mat,1,mean);
    if (statistic=='mean.diff'){
      teststat=mean.treated.r-mean.control.r;
    }else if (statistic=='t.test'){
      var.treated.r=apply(treated.r.mat,1,var)
      var.control.r=apply(control.r.mat,1,var)
      pooledsd=((m-1)*var.treated.r+(N-m-1)*var.control.r)/(N-2)
      teststat=(mean.treated.r-mean.control.r)/pooledsd
    }else{
      stop('statistic must be one of mean.diff and t.test')
    }
    
    # p-value
    if (alternative=='greater'){
      pval=sum(teststat>=obs.test.stat)/length(teststat)
    }else if (alternative=='less'){
      pval=sum(teststat<=obs.test.stat)/length(teststat);
    }else if (alternative=='two.sided'){
      pval=sum(teststat>=abs(obs.test.stat))/length(teststat)+
        sum(teststat<=-abs(obs.test.stat))/length(teststat);
    }else{
      stop('alternative needs to be one of greater, less, and two.sided.')
    }
    list(pval=pval,teststat=teststat,obs.test.stat=obs.test.stat)
  }else{
    # Monte Carlo simulation 
    montecarlo.test.stat=rep(0,n.mc);
    for(i in 1:n.mc){
      treatedgroup=sample(1:N,m);  # Draw random assignment
      controlgroup=(1:N)[-treatedgroup];
      # Compute test statistic for random assignment
      if (statistic=='mean.diff'){
        montecarlo.test.stat[i]=mean(r[treatedgroup])-mean(r[controlgroup]); 
      }else if (statistic=='t.test'){
        var.treated.r=var(r[treatedgroup])
        var.control.r=var(r[controlgroup])
        pooledsd=((m-1)*var.treated.r+(N-m-1)*var.control.r)/(N-2)
        montecarlo.test.stat[i]=(mean(r[treatedgroup])-mean(r[controlgroup]))/pooledsd
      }else{
        stop('statistic must be one of mean.diff and t.test')
      }
    }
    # Monte Carlo p-value
    if (alternative=='greater'){
      pval=sum(montecarlo.test.stat>=obs.test.stat)/n.mc
    }else if (alternative=='less'){
      pval=sum(montecarlo.test.stat<=obs.test.stat)/n.mc
    }else if (alternative=='two.sided'){
      pval=sum(montecarlo.test.stat>=abs(obs.test.stat))/n.mc+
        sum(montecarlo.test.stat<=-abs(obs.test.stat))/n.mc;
    }else{
      stop('alternative needs to be one of greater, less, and two.sided.')
    }
    # 95% CI for true p-value based on Monte Carlo p-value
    lowerci=pval-1.96*sqrt(pval*(1-pval)/n.mc);
    upperci=pval+1.96*sqrt(pval*(1-pval)/n.mc);
    list(pval=pval,lowerci=lowerci,upperci=upperci,
         mc.test.stat=montecarlo.test.stat,
         obs.test.stat=obs.test.stat)
  }
}
